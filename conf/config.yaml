random_seed: 42
training:
  normalization_stats_path: normalization_stats.npz
  tensorboard_log_dir: logs/%Y-%m-%d_%H-%M-%S/
  gcbc_window_length_min: 32
  gcbc_window_length_max: 64
  lmp_window_length: 64
  batch_size: 256
  mixed_precision_policy: p=f32,c=bf16
  optimizer:
    _target_: optax.adamw
    learning_rate: 1e-3
  num_steps: 100000
  method: play-gcbc
  beta: 0.01
model:
  d_obs: 59
  d_latent: 64
  d_action: 9
  target_action_max:
    _target_: jax.numpy.ones
    _args_:
      - ${model.d_action}
  target_action_min:
    _target_: jax.numpy.full
    _args_:
      - ${model.d_action}
      - -1.0
  plan_recognizer:
    _partial_: true
    _target_: play_lmp.BidirectionalLSTMPlanRecognitionNetwork
    d_obs: ${model.d_obs}
    d_action: ${model.d_action}
    d_latent: ${model.d_latent}
    hidden_size: 1024
  plan_proposal:
    _partial_: true
    _target_: play_lmp.MLPPlanProposalNetwork
    d_obs: ${model.d_obs}
    d_latent: ${model.d_latent}
    width_size: 512
    depth: 3
  policy:
    _partial_: true
    _target_: play_lmp.LSTMPolicyNetwork
    d_obs: ${model.d_obs}
    d_latent_plan: ${model.d_latent}
    d_action: ${model.d_action}
    hidden_size: 2048
    num_dl_mixture_elements: 6
    action_max_bound: ${model.target_action_max}
    action_min_bound: ${model.target_action_min}
    num_action_bins: 256
